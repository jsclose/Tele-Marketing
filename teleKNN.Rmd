---
title: "Homework 5"
author: "Jake Close & Peter Kaplan"
date: "10/26/2017"
output: html_document
---


First lets read in the dataset and observe the structure.
```{r}
library(dummies)
library(class)
library(gmodels)
#the data is split by semi colon, not a comma.
tele <- read.csv("telemarketing.csv", sep = ";")
str(tele)
```

Also, lets observe the current proportion of our target value: has the client subscribed a term deposit?

```{r}
round(prop.table(table(tele$y)) * 100, 1)
```
We see that there is a base of 88.7 % people saying no. Therefore, our model should be atleast this accurate in order to be useful.


Lets find out which variables have missing data and see if we can account for that.
```{r}
colSums(is.na(tele))
```
We find there are no missing data.

Lets explore the general statistics of the data.
```{r}
summary(tele)
```
For the column pdays: number of days that passed by after the client was last contacted from a previous campaign, we know that  (numeric; 999 means client was not previously contacted). In order to use this in our model, we should account for this. For now, we will remove.




Next we will remove the duration column. This is because when we are predicting if a phone call will succeed or not we don't know the duration. Before we remove it, lets check to see how duration varies between yes' and nos. 
```{r}

boxplot(duration~y,data=tele, main="Duration of Calls vs. Success", 
  	xlab="Successful Sale", ylab="Duration of Call (seconds)", outline=FALSE)

#tele <- tele[-11]

```
As we can see, when a person stays on the phone longer it is more likely to be successful. This makes sense as talking for longer usually indicates interest.

Lets prepare the datset for KNN.

Lets convert the output variable to a numeric.

Need to clean factor values to only have unique levels for later creation of dummy variables.
```{r}
#convert output to numeric
tele$y <- as.numeric(tele$y)
levels(tele$housing) <- c("housing_no","housing_unknown","housing_yes")
levels(tele$loan) <- c("loan_no","loan_unknown","loan_yes")
levels(tele$default) <- c("default_no","default_unknown","default_yes")


levels(tele$job)[match("unknown", levels(tele$job))] <- "job_unknown"
levels(tele$job)

```


Convert Factor Variable to dummy variables.
We create a for loop that goes through each factor and converts them to dummy variables.
We also keep track of these variables and then drop them after.
```{r}


drops <- c("duration", "pdays")
for (col in names(tele)){
  if(class(tele[[col]]) == "factor" && col != "y"){
      tele <- cbind(tele, dummy(tele[[col]], sep = "_"))
      drops <- c(drops, col)
  }
}

tele <- tele[ , !(names(tele) %in% drops)]
#df1 <- cbind(tele, dummy(tele$contact, sep = "_"))
#str(tele)
```


Lets split the data into training and testing datasets. Lets do a 25/75 split

Choose k  = sqrt(dataset size ) = 203
```{r}

#drop y from our training data
tele_n <- tele[ , !(names(tele) %in% c("y"))]

#scale using z score
tele_n <- as.data.frame(scale(tele_n))


#create training data and testing data subset
tele_train <- tele_n[10297:41188, ]
tele_test <- tele_n[1:10297, ]

#create labels
tele_train_labels <- tele[10297:41188, 20 ]
tele_test_labels <- tele[1:10297, 20 ]



#create prediction, with k ~ sqrt(41k) = 203
tele_test_pred <- knn(train = tele_train, test = tele_test,
                      cl = tele_train_labels, k=203)
#cross
CrossTable(x = tele_test_labels, y = tele_test_pred, 
           prop.chisq=FALSE)
```

Analysis:

Want to minimize false negatives. Our prediction defaults to "not going to buy", therefore we do not want any opportunity lost.

We find in our Cross table that we have minimized the amount of false positives. 
We find that that our accuracy is 99.89%.
